# Group N Report SLEAC
## University of Reading

Module Code: CS3SC17<br>
Assignment report Title: <insert your topic areas here><br>
Student Numbers: 27015244, 28000034, 27003132, 28019806, 28010356<br>
Date (when the work completed):<br>
Actual hrs spent for the assignment:<br>
Assignment evaluation (3 key points): TBD<br>

## Introduction

The main topic of the report involves the general implications and considerations required as robotics become more sophisticated. A plethora of different sectors are considered within the context of social, legal and ethical considerations and how it will impact society in the future. Subtopics include the military, police and health. We watched a movie called 'Alita: Battle Angel', based on a future with advanced technologies and robotics. The movie provided a good comparison to the current state of robotics outlining potential approaches to how humans would live amongst these machines. The film was able to convey a diverse group of areas robotics could be utilised including the military, police and health care. It also considers how where the responsibilty lies with regards to these machines as well as analysing the decision processes the robots would take. 

## Analysis

### Government

WW2 is a great example of the first use of robotics in warfare. Robots, like US's 'Aphrodite' drones were not effective in carrying out every task that their commanders have ordered them to do. It wasn't until the 1990's that robotics for military operations fully commenced with the MQB-1 Predator drone used by the CIA. These drones could be controlled by satellite through any command post to cover intelligence gaps. Whilst the progress in making the robots intelligent from 1940s to the 1990s is quite incredible, such robots don't have the capacity to react appropriately in unpredictable scenarios. This has a lot of legal issues behind this as this could lead to the human personnel getting involved to stop the robots from causing unwanted damage. If we were to develop a body like the 'Berserker' in 'Alita: Battle Angel', it would have ethical, legal and social impacts. 

Firstly, the method of connecting the human head to a robotic body could be potentially seen as ethically and morally wrong. This is because religions such as Islam dictate that the human body should be treated with the upmost respect and no harm should come to it. To further add to this point, even if it was possible to connect a human head to a robotic body, there would be the question of how reliably the body and mind would be able to interface. This is directly addressed in Alita's flashbacks, we can see that similar 'Berserker' soldiers along with Alita are planning and coordinating their attacks in a war of some kind in order to deal with the enemy. From this, we can infer that the robots must have had a variety of situational training to deal with such scenarios and ultimately make decisions for themselves. This could bring into question whether every decision they make will always be the right one and thus 'technically say' that it's the robot's responsibility for the decisions that are made. 

Secondly, public trust in the robots and the robotics industry would be under close scrutiny as any industry developing robots have an associated fear within the perceptions of the public regarding mankind’s survivability, which causes the public to have concerns. For example, if the robots from 'Alita: Battle Angel' were to be sent to war, there might be the potential for the robots to be hijacked. This could be seen as catastrophic as this would lead to more civilian casualties from both sides and could further push the fear of robots. Therefore, the companies that designs these machines needs to convince the general public that the machines have the necessary protection systems and features that will work properly and will keep the public safe. It also brings into question what regulations goverments would enforce regarding the capabilities of robots.

Thirdly, it may be true that new strategies, tactics, and technologies make armed conflict an easier path to
choose for a nation only if risks are decreased on our side. Yet while it seems apparent that we should want to decrease casualties from our respective nations, there is something justifiable about the need for some terrible cost to war as a means against engaging in war in the first place. The considered objection, that the use of war robots immorally lowers barriers for war, implies that no actions should be taken that makes war more favourable. Examples include that we should not attempt to reduce friendly deaths, to improve warfare medicine or carry out further research that would increase the chances of a quicker victory. If this idea is taken to the extreme, it suggests that we should raise the barriers to war, to make the fighting as violent as possible such that we would never get involved unless if it was truly the last resort. This kind of idea would be foolish in the worst case scenario and most likely counterintuitive in the best case scenario, especially if were to assume that the other countries would not be ready to give up fighting. This will severely put the country that makes the war robots at a competetive disadvantage.

On the other hand, war robots do have benefits to both military and civilian personnel alike. In a war scenario, there will be several types of obstacles in the way and tight spaces to squeeze past. War robots can fit into such spaces that would be otherwise inaccessible for a human being and thus gain a strategical advantage against the enemy. Furthermore, war robots can help in saving the lives of injured human soldiers and can take damage impact, such as from a bomb explosion, that would normally severely injure or kill a human soldier. On top of this, war robots can be easily mass produced and upgraded to deal with a variety of situations more efficiently. This is much better than trying to constantly train human soldiers to deal with such situations. Finally, war robots can survive in extremes that would otherwise kill a human such as nuclear waste sites, very hot places and very cold places.

It has also been shown that the question of armed autonomous machines within the context of law enforcement services. There are a lot of implications with law enforcement utilising robots for situations that may involve the use of weapons. The primary issue with this is potentially allowing an individual's life to be determined by an algorithm. Given robots do not have conscience their actions are determined by algorithms they are programmed with. Due to the exact nature of an algorithm this removes context from situations which could lead to an increase in deaths caused by law enforcement services. It also leads to the question of who's at fault in the situation of an error.

Armed robots for law enforcement also cause a shift in the social view of law enforcement, with a larger adoption of machines for law enforcement purpose this could cause a de-humanisation of the law enforcement. De-humanisation could lead to a greater divide between the people and the Government, this is evident already from reports.
>New York City councilmember Ben Kallos says he "watched in horror" last month when city police responded to a hostage situation in the Bronx using Boston Dynamics' Digidog, a remotely operated robotic dog equipped with surveillance cameras.

Key questions with regards to the legality autonomous machine are already being considered such as what "Reasonable force" would be for a machine. Some areas are even creating legal documents to directly address this issue such as within New York.

There is also the social aspect of robotics being used within the police force. The key concern here is whether a machine would enforce true equality. Depending on the data that the machines have been trained on there could be potential bias within the data leading to inequality when it comes to correctly identify illegal activity. This presents the problem of how to handle human bias within a machine. Given a situation where a human officer would have to make a decision that would reflect their personality, a machine is unable to reason to this degree and could lead to incorrect outcomes.

Despite the concerns surrounding the implementation of autonomous machines within the police force there are several potential benefits to this approach. The main benefit of using a machine in place of a human is it reduces the frequency of casualties for the police force. Similarly allowing machines to deal with the more dangerous situations it would allow human officers to focus more on the general wellbeing of the public. Another viewpoint could be due to the algorithmic nature of machines there may be a social perception that machines are more consistent and efficient in contrast to the viewpoint that police officers are lazy, there is also the idea that a robot would have less error in comparison to a human officer, whilst this isn't necessarily true the general perception of robots is that they are consistent and accurate.

### Minds

As the world tries to find newer and more efficient ways of creating robotics, one of the main topics involving robotics is the ability for them to evaluate situations similar to a human's thought process. Due to the robotics being programmed as algorithms to be used on everyday tasks or specific tasks, scientists are outlining how a robot can be taught to navigate a maze by using electric flows serving as brain nerve cells connected to the machine.

Whilst it could be considered morally wrong with some religions due to the view of playing as 'god' it's also ethically wrong as the question goes; will robots be able to tell the difference between us and them? In the movie 'Alita: Battle Angel', it is shown the world being insanely advanced technologically and shows robotics in the form of citizen protection. If these sort of robotics existed in the real world, it would arise many questions, one being will it be able to make the correct choice instead of following a script such as if criminal, arrest as the movie showed a similar situation to which the robot followed through the wrong decision for the plot. This shows the robot was following an algorithmic mindset instead of being able to process like us and seeing how an algorithm can be faulty, giving robotics the ability to make their own decisions and 'live' will cause robotics to step away for the real purpose their created.  Another seen in the movie shows the robot almost stepping on a dog and the main character, showing we humans would have to avoid the robots as they won't think of us as objects to avoid.

Alongside the negatives surrounding robotic decision processes, it can also be beneficial. As shown in the movie, the robotics in role protect most civilians and is used as a way of protection as the movie also references that the police do not exist and is about bounty hunters and these protecting machines. If these machines were to be implemented in real life situations it can protect people and reduce crime in the future. Alongside cyborgs existing, while having the ability to think like us, it means these cyborgs can live amongst us and also help us with daily tasks and more.

### Medicine & Rehabilitation

Throughout the movie “Alita: Battle Angel”, we see a substantial advancement in medicine and rehabilitation using AI and robotics. Some of the main advantages shown whilst using AI and robotics in clinical practices was that there is a reduction in human errors, more precise diagnosis and a more reliable way of monitoring patient’s records/progress. 

Although, the use of robotics and AI holds many advantages, we need to consider legal aspects when introducing robots and AI into healthcare. One factor to consider is liability if an error or a malfunction occurs in the system, which can potentially cause physical harm to patients or even clinicians, during a procedure or prescription. This may also lead to ethical issues being addressed when deciding on who the responsibility lies with when there is a malfunction in the system that has caused harm to someone. An example of when a malfunction occurred whilst using AI in the medical field is IBM’S “Watson for Oncology”. In 2013, IBM and The University of Texas MD Anderson Cancer Centre partnered together to create an Oncology “expert advisory” system in order to reduce and cure cancer. This in turn resulted in the discovery that the system was giving harmful cancer treatment advice because the data being used in the system were not collected from real life cancer patients and were tested from a hypothetical cancer patient standpoint. Therefore, laws need to be put in place in order to protect patients' experience with robotics and AI healthcare and also allow for creators to think about ethical issues when making these AI systems and robots. In the case of IBM’s “Watson for Oncology” program, the IBM’s engineers were mostly blamed for the failure of the system but is it fair to hold mainly the engineers entirely accountable?

This type of data error or malfunction, demonstrated in IBM’s “Watson for Oncology”, also raises ethical issues as it falls under the four pillars of medical ethics such as justice. Justice needs to be considered when creating algorithmic AI systems as there could be a risk with AI being biased and therefore lead to discrimination. This is because AI systems are merely human-trained algorithms that could potentially include datasets from a biased standpoint.

Another legal issue arising when considering using AI systems in healthcare is cybersecurity. This means that as technology progresses and patient's data is being processed, there is a risk of hackers who can steal patient's information or manipulate data. This also brings up ethical topics such as patient confidentiality and falls under the medical pillars, the patient's autonomy. Manipulated data in the AI algorithmic system can also cause harm to the patient's wellbeing due to misinformation from the corrupted systema and breach patient’s confidentiality. This means laws need to be put in place to make sure data is being stored safely and there are good cybersecurity frameworks put in place. Furthermore, patients need to be informed on how and where their data is being used and stored and allow whether the patient wants to give consent for their data to be used.

Whilst many people don't mind the idea of using AI systems and robotics for their healthcare procedures, social issues such as the patient's surgeon and rehabilitation counsellor preference is something to consider as some people may have misconceptions about the use of AI systems and robots or may just prefer to have a patient-clinician relationship.

As technology continues to improve it gradually becomes embedded within all sectors. The medical sector is a clear example of this, a key area of artificial intelligence for computer vision is to identify medical images. The current technology within the medical sector predominantly acts as an assistant for a qualified individual.
>The robotic system in surgery is currently a robotic-assisted operation; a slave device that is nothing more than a tool and an extension of the surgeon (12).

Whilst fully autonomous machines are not used within surgeries currently there are still a significant number of factors to evaluate if it could be achieved. From the perspective of the general public there are several different perspectives to be considered and how comfortable a patient would feel being treated by a robot reflect this. From one perspective there could potentially be a lack of trust in the machine in performing the surgery needed, this could be due to a lack of faith within the technology the robot consists of. 

Another consideration is how to establish when a machine is suitable enough to be deployed within a real environment. For surgeries that could lead to fatality if done wrong how would a robot be trained to handle the situation, further to this point how certain can a manufacturer be that the training transfers directly to operating on a human patient.

## Issues arising from using modern robotics in our daily lifestyle

Society has always been concerned about the impact of modern robotics on the normal life. There are bunch of positive features which may help for reduction in human errors, developing the level of digital assistance, inventing new and faster technologies and others but at the same time there are some arising issues that may reflect seriously on the world community.

Examples of severe consequences of the modern robotics and AI can be noticed in the movie ,,Alita: Battle Angel’’ 2019 which is mainly focused on presenting how people live along with robots and other AI technologies several centuries in the future.

If we refer to some common situations in the movie, we can see that robots and AI are used on an equal footing with humans and participate in any kind of activities related to jobs, sports, entertainments, and others. The film demonstrates that robots play an integral role of the life on the planet and people have already allowed them to be too close to their habitat. However, we can notice a large number of scenes, proving that the excessive trust of modern robotics might have a serious counter-effect over the civilization as AI and robots can even become dangerous for people.
All companies that produce AI and work with modern robotics try to implement the risk management bеyond legal requirements in order to reduce the chance of accidents that may lead to serious damages to their reputation. Engineers, from such companies, who deal with AI realize that modern robotics can be a huge risk not only for them but for the genеral public.

Underneath are some serious issues that may lead to counter-effect over robots:
- possibilities of programming errors occurrence, faulty algorithms, loss of connection and others could make robots unpredictable and even dangerous for people themselves. 
- incorrect assembling of robot parts could make it functions wrong. For example, some power sources that have a direct communication with robots can bе disrupted because of the above-mentioned problem, hence this can produce an energy releasing in the atmosphere.
- mechanical failures should also be considered during the robot design stage because this mistake can also lead to a potentially dangerous situation for the surrounding people.

Those are the issues that could only be caused by inattention or lack of observance of the details. Below are listed some essential problems that are not a result of a human error in parts assembling or programming bugs in the algorithm of the robot management. The presented issues concern the whole way of humans’ life in social, legal and ethical aspects such as growing dehumanization in physical facilities and stores, disappearance of jobs, misinformation and fake news, lack of trust and others .
(THE SECTION IS NOT READY YET!)

## Conclusion

This report has established that a significant amount of consideration must be taken into account as the proficiency and ability of autonomous machines develop. A key aspect is the social impact these machines could provide as well as how society perceives these developments. These developments span a large range of sectors and has the potential to change how people operate daily. One common point established is societies current reservations surrounding machines replacing humans in particular roles due to the fear of faults. Similarly, as the roles machines occupy within society become more important, regulations will need developing to restrict how much ability machines have. Another point discussed in this report is although robots and AI are being used to reduce human error, AI systems and robots are algorithms trained on datasets that may not represent every demographic of a population, which will lead to biases and discrimination. It is crucial that as these machines develop a wide range of perspectives are considered to bring the greatest benefit to society.

## References

* [Batarseh, A. F., Kumar, A. LSE (2020, February 17). The use of robots and artificial intelligence in war.](https://blogs.lse.ac.uk/businessreview/2020/02/17/the-use-of-robots-and-artificial-intelligence-in-war/)
* [Lin, P., Bekey, G., Abney, K. (2009). Robots in War: Issues of Risk and Ethics.](https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1010&context=phil_fac)
* [Soffar, H. Online Sciences (2019, June 22). Army robots types, advantages, disadvantages & how do Artificial soldiers change the future of war?](https://www.online-sciences.com/robotics/army-robots-types-advantages-disadvantages-how-do-artificial-soldiers-change-the-future-of-war/)
* [WIRED (2021). New York lawmaker wants to ban police use of armed robots.](https://arstechnica.com/tech-policy/2021/03/new-york-lawmaker-wants-to-ban-police-use-of-armed-robots/, "Ban of Police using robots")
* [The ethics of robotic surgical systems is a conversation of informed consent](https://vats.amegroups.com/article/view/5469/html)
* [A Local Law to amend the administrative code of the city of New York, in relation to prohibiting the police department from using a robot armed with a weapon](https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4856756&GUID=716C2D7E-ED51-4C9E-9312-AB9529B6C812&Options=ID%7cText%7c&Search=, "Local law regulating use of armed robots within police")
* [Robotics in Policing Review](https://www.uclalawreview.org/policing-police-robots/, "Robotics in Policing Review")
* [Intelligence, A., 2020. Stories of AI Failure and How to Avoid Similar AI Fails - Lexalytics.](https://www.lexalytics.com/lexablog/stories-ai-failure-avoid-ai-fails-2020).
* [Gerke, S., Minssen, T., &amp; Cohen, G. (2020, June 26). Ethical and legal challenges of artificial intelligence-driven healthcare. Artificial Intelligence in Healthcare.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7332220/). 
* [Wightman, S. C., David, E. A., Atay, S. M., Kim, A. W., &amp; Angelos, P. (2020, March 17). The ethics of Robotic Surgical Systems is a conversation of informed consent. Video-Assisted Thoracic Surgery.](https://vats.amegroups.com/article/view/5469/html).
* [The robots are coming!](https://www.insurancejournal.com/magazines/mag-features/2013/10/21/308188.htm).
* [Miguel González-Fierro (2018, April 1). Ethical Issues Of Artificial Intelligence And Robotics.](https://miguelgfierro.com/blog/2018/10-ethical-issues-of-artificial-intelligence-and-robotics/).
* [(2019, September 28). The three laws of robotics have failed the robots.](https://mindmatters.ai/2019/09/the-three-laws-of-robotics-have-failed-the-robots/).    




